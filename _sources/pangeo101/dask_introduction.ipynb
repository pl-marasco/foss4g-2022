{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfbae7a-12f1-4787-a520-c3de7529168d",
   "metadata": {},
   "source": [
    "# Parallel computing with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bb79b-1b06-42c9-98d5-6185252c86e5",
   "metadata": {},
   "source": [
    "## Authors & Contributors\n",
    "### Authors\n",
    "- Tina Odaka, Ifremer (France), [@tinaok](https://github.com/tinaok)\n",
    "### Contributors\n",
    "- Pier Lorenzo Marasco, Ispra (Italy), [@pl-marasco](https://github.com/pl-marasco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245decb-8706-4b55-aead-79dd7a621bdd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<i class=\"fa-question-circle fa\" style=\"font-size: 22px;color:#666;\"></i> Overview\n",
    "    <br>\n",
    "    <br>\n",
    "    <b>Questions</b>\n",
    "    <ul>\n",
    "        <li>What is Dask?</li>\n",
    "        <li>How can I parallelize my data analysis with dask?</li>\n",
    "    </ul>\n",
    "    <b>Objectives</b>\n",
    "    <ul>\n",
    "        <li>Learn about dask</li>\n",
    "        <li>Learn about dask gateway, dask client and dask worker</li>\n",
    "        <li>Understand out-of-core and speed-up limitations</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c3e5a-1ddf-4178-a05e-2ce711ab1b8b",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "\n",
    "We will be using [dask](https://docs.dask.org/) with Xarray to parallelize our data analysis. The analysis is very similar to what we have done in previous episodes but this time we will use data on a global coverage that we read from a shared catalog (stored online in the Pangeo EOSC OpenStack Object Storage).\n",
    "\n",
    "### Data\n",
    "\n",
    "In this episode, we will be using Global Long Term Statistics (1999-2019) product provided by the [Copernicus Global Land Service over Lombardia](https://land.copernicus.eu/global/index.html) and access them through [S3-comptabile storage](https://en.wikipedia.org/wiki/Amazon_S3) ([OpenStack Object Storage \"Swift\")](https://wiki.openstack.org/wiki/Swift) with a data catalog we have created and made publicly available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c600794-dd9e-400b-bd09-dbb6e7039dad",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This episode uses the following Python packages:\n",
    "\n",
    "- pooch\n",
    "- s3fs\n",
    "- xarray\n",
    "- netcdf4\n",
    "- h5netcdf\n",
    "- hvplot\n",
    "- dask\n",
    "- graphviz\n",
    "- numpy\n",
    "- pandas\n",
    "- geopandas\n",
    "\n",
    "Please install these packages if not already available in your Python environment. Below, we only install packages that are not available in the EGI-ACE EOSC deployment of Pangeo for the FOSS4G course.\n",
    "\n",
    "### Packages\n",
    "\n",
    "In this episode, Python packages are imported when we start to use them. However, for best software practices, we recommend you to install and import all the necessary libraries at the top of your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd73e3-0120-4457-b84b-ccd9325a72a6",
   "metadata": {},
   "source": [
    "## Parallelize with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35db696-501a-4110-a7fa-fafe92dfc0a2",
   "metadata": {},
   "source": [
    "We know that chunking is key for analyzing large datasets and in this episode, we will learn to parallelize our data analysis using dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f3544-8b08-462d-b8a4-c6c0c2f68a26",
   "metadata": {},
   "source": [
    "### What is Dask?\n",
    "\n",
    "**Dask** accelerates the existing Python ecosystem: with very or no changes in your code, you can speed-up computation using Dask.\n",
    "\n",
    "- Dask is a flexible library for parallel computing in Python.\n",
    "- It is widely used for getting the necessary performance when handling large and complex Earth Science datasets.\n",
    "- Dask is powerful, scalable and flexible. It is the leading platform today for analytics.\n",
    "- It scales natively to clusters, cloud and bridges prototyping up to production.\n",
    "- The strength of Dask is that is accelerates the existing Python ecosystem e.g. Numpy, Pandas and Scikit-learn with few effort from end-users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44c561-da09-4051-b562-bca3c276659e",
   "metadata": {},
   "source": [
    "#### How does Dask accelerate your data analysis?\n",
    "\n",
    "- Dask chunks your big datasets and this is how we can easily parallelize and scale.\n",
    "\n",
    "For instance, dask can chunk a large numpy array into smaller ones and compute each chunk independently.\n",
    "\n",
    "![Dask and Numpy](https://examples.dask.org/_images/dask-array-black-text.svg)\n",
    "\n",
    "The same applies for `Xarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9fd40-08f4-43e2-897f-b1e745fd215a",
   "metadata": {},
   "source": [
    "#### How does Xarray with dask distribute data analysis?\n",
    "\n",
    "When we use chunks with `Xarray`, the real computation is only done when needed; for instance when invoking `compute()` function. Dask generates a **task graph** describing the computation to be done and a **scheduler** executes these tasks across several **workers**.\n",
    "\n",
    "![Xarray with dask](../figures/dask-xarray-explained.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650891a-d855-4117-88de-ebaacc7620fb",
   "metadata": {},
   "source": [
    "## Set up dask gateway\n",
    "\n",
    "There are different ways to use dask depending on the underlying infrastructure. In the Pangeo EOSC you are using for this workshop, we have the possibility to set up dask gateways to manage dask clusters and run our data analysis in parallel e.g. distribute tasks across several workers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db87819-fae0-439b-a907-1d03ede15ba4",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "gateway = Gateway(\n",
    "    \"http://api-daskhub-dask-gateway.daskhub:8000/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090de940-ad6e-41d9-aada-c97c569a79d0",
   "metadata": {},
   "source": [
    "## Create a new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4ce66-a4a3-4666-9d55-5768837f4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbd1a5-3999-46c8-a052-69ceef1263ff",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster()\n",
    "cluster.scale(4)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7adaa-1964-42ae-bf94-435a9038accc",
   "metadata": {},
   "source": [
    "## Get a client from the Dask Gateway Cluster\n",
    "The Dask client is what allows you to interact with Dask. \n",
    "The Client will create the Directed Acyclic Graph (DAG) of tasks by analysing the code, and will be responsible for telling the scheduler what to compute. It will also gather results from the workers and aggregates the results in the Client process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d95b48-e5a2-46a2-8921-05d9fb796885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "\n",
    "if cluster:\n",
    "    client = Client(cluster) # create a dask Gateway cluster\n",
    "else:\n",
    "    client = Client()   # create a local dask cluster on the machine.\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4ff9d-b390-49f9-a0e6-622170d955af",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "A Dask client can also be created on a single machine (for instance your laptop) e.g. there is no need to have dedicated computational resources. However, speedup will not be possible if you do not have dedicated computational resources!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb4594-f755-474c-bad8-f783345dc96b",
   "metadata": {},
   "source": [
    "## Open a single file for parallel processing\n",
    "\n",
    "We will first open a sngle file: we use the same syntax as earlier but this time, we pass an additional parameter `chunks` to explicitely define how the chunking (and then parallel computing) needs to be done. \n",
    "- `-1` for time means the dataset is loaded with dask using a single chunk for all arrays;\n",
    "- `auto` will use dask auto chunking taking into account the engine preferred chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cc166-4213-4fd5-be45-ae3b9f2697db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f7e3b-4d8f-403e-9b2f-347c54a54d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=True,\n",
    "      client_kwargs={\n",
    "         'endpoint_url': 'https://object-store.cloud.muni.cz'\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a47e8-6658-43eb-87c2-286c8394832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s3path = 's3://foss4g-data/CGLS_LTS_1999_2019/c_gls_NDVI-LTS_1999-2019-1221_GLOBE_VGT-PROBAV_V3.0.1.nc'\n",
    "LTS = xr.open_dataset(fs.open(s3path), chunks={'time':-1, 'lat':'auto', 'lon':5000})\n",
    "LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171f9b8-eb49-43ee-9d3f-5b8d74434e1f",
   "metadata": {},
   "source": [
    "## Select a single location and visualize the task graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7190e-5596-413c-a066-cfe214e933f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save=LTS.sel(lat=45.50, lon=9.36, method='nearest')['min']\n",
    "save.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08b90d-22d6-404f-8c3d-3c557410d601",
   "metadata": {},
   "source": [
    "If you look to the task graph, you can see that only one dask worker need to read the data so most dask workers are doing some useless reads of data. \n",
    "We optimise, and verify the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77254f5a-7001-4fcd-a88e-af4e9a6d96fd",
   "metadata": {},
   "source": [
    "## Optimize the task graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6888b-de87-4989-8975-50a0d2a1fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a103cc3-5cda-41b8-85e6-3a06eb8e3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(save,)=dask.optimize(save)\n",
    "save.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ae3c7-e84d-48be-8a25-40b5d504ae3e",
   "metadata": {},
   "source": [
    "## Install missing packages on the dask workers\n",
    "The workers have their own conda environment, independent from what we have in our notebook. Most of the time, the workers do not have many Python packages installed by default (this is often not needed). Therefore, to be able to compute anything, we need to make sure the packages needed for the corresponding computation are available on the worker of the dask cluster. If not, using `.compute()` will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c38ffa-2124-485a-8f18-0ad0c85c9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed.diagnostics.plugin import PipInstall\n",
    "\n",
    "extra_packages=[\"xarray\", \"netCDF4\", \"s3fs\", \"h5netcdf\", \"zarr\"]\n",
    "\n",
    "plugin=PipInstall(extra_packages,restart=True)\n",
    "client.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596d9c1-226a-4e9e-a49b-c99f85b42935",
   "metadata": {},
   "source": [
    "Verify the installation of package on dask worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63f777-d36a-468c-9074-30e765b5c569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.get_versions(packages=extra_packages,check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698f61f-32bf-4ccc-bfcf-2f58de316431",
   "metadata": {},
   "source": [
    "## Compute on the dask workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45148205-16b9-42a4-aaba-938c5cea593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4818f-2b6b-44c1-af77-97daf8a1c2a1",
   "metadata": {},
   "source": [
    "## Global LTS\n",
    "\n",
    "In the previous episode, we used Long-term Timeseries for the region of Lombardy e.g. a very small area. Now we would like to use the original dataset that has a global coverage. Let's first open one single file (for January 1999-2019) to understand how much larger the global dataset is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e33d9-f980-4416-a3e4-07689d5bf1a8",
   "metadata": {},
   "source": [
    "## Read from online catalog\n",
    "The catalog can be shared on cloud and load it from there too. We will access Long Term TimeSeries of NDVI statistics from OpenStack Object Storage through the kerchunked catalog (see previous episode on catalogs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655225ff-99fd-45cb-a31f-606335e39b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abef70-69fb-4611-84b4-40854075d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue=\"https://object-store.cloud.muni.cz/swift/v1/foss4g-catalogue/c_gls_NDVI-LTS_1999-2019.json\"\n",
    "LTS = xr.open_mfdataset(\n",
    "    \"reference://\", engine=\"zarr\",\n",
    "    backend_kwargs={\n",
    "        \"storage_options\": {\n",
    "            \"fo\":catalogue\n",
    "                    },\n",
    "        \"consolidated\": False\n",
    "    }\n",
    ")\n",
    "LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b09b2-a66b-4da5-af17-24e2c64325f8",
   "metadata": {},
   "source": [
    "### Fix time coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49abb7-411f-4613-94d7-1bd904ed07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_2022 = pd.date_range('20220101', '20221231')\n",
    "decadie = dates_2022[np.isin(dates_2022.day, [1,11,21])]\n",
    "LTS = LTS.assign_coords(time=decadie)\n",
    "LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e1ce3-bd72-40f2-ae6b-c51a8be352fe",
   "metadata": {},
   "source": [
    "## Clip LTS over Lombardia\n",
    "\n",
    "As in previous episodes, we use a shapefile over Lombardia to select data over this Area of Interest (AOI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffd88b-6eb8-45d9-ad26-fdb3ca7af507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d1165-7b57-45fd-b9ed-05046ce286c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    GAUL = gpd.read_file('Italy.geojson')\n",
    "except:\n",
    "    GAUL = gpd.read_file('zip+https://mars.jrc.ec.europa.eu/asap/files/gaul1_asap.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363bafb-551a-4a25-8793-b854cefc071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI_name = 'Lombardia'\n",
    "AOI = GAUL[GAUL.name1 == AOI_name]\n",
    "AOI_poly = AOI.geometry\n",
    "AOI_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6be2f-48c7-4913-814d-4f2bef01323b",
   "metadata": {},
   "source": [
    "We first select a geographical area that covers Lombardia and then clip using the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90237f5e-f7e4-4ec1-934c-2c6bd5dd2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS = LTS.sel(lat=slice(46.5,44.5), lon=slice(8.5,11.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe014a-8bd8-4b9e-8a4b-c3cdda63833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS = LTS.rio.write_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbfab2-a11a-46f2-858c-4c336ad76bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS = LTS.rio.clip(AOI_poly, crs=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b1526-eadf-49a8-8994-e5b85d03bceb",
   "metadata": {},
   "source": [
    "### Print metadata\n",
    "We can print metadata without performing any computation yet. This is what we call *lazy* computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503edd2-cfc7-4f8c-a06e-481e63527ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bced0fa-d5d2-4e28-8ea9-29ecdd20a722",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce33190-c584-4733-8e31-4114cafd3c1c",
   "metadata": {},
   "source": [
    "### Install additional packages in dask workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3e549-f1bc-42aa-8052-ad5afa8a2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_packages=[\"xarray\", \"netCDF4\", \"s3fs\", \"h5netcdf\", \"numpy\", \"zip\", \"pandas\", \"geopandas\", \"rioxarray\", \"rasterio\", \"scipy\", \"zarr\"]\n",
    "\n",
    "plugin=PipInstall(extra_packages,restart=True)\n",
    "client.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35969623-39a1-4ea2-bf4b-136b2225ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LTS_min = LTS['min']\n",
    "(LTS_min,)=dask.optimize(LTS_min)\n",
    "LTS_min.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e7b50-1ecd-4898-8350-d6b98f471f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LTS_min.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801e8ac-137b-4eeb-bb89-280ed8b9bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LTS_max = LTS['max']\n",
    "(LTS_max,)=dask.optimize(LTS_max)\n",
    "LTS_max.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c3bcf-61e0-4262-9efc-a132d81ca0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LTS_max.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18285df-862d-487c-ab2f-57823907a3f1",
   "metadata": {},
   "source": [
    "## Get NDVI for 2022 over Lombardia\n",
    "\n",
    "We re-use the file we created during the first episode. If the file is missing it will be downloaded from Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d333a4-228c-4eff-9252-94e13c0a7828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pooch\n",
    "try:\n",
    "    cgls_ds = xr.open_dataset('C_GLS_NDVI_20220101_20220701_Lombardia_S3_2_masked.nc')\n",
    "except:\n",
    "    cgls_file = pooch.retrieve(\n",
    "        url=\"https://zenodo.org/record/6969999/files/C_GLS_NDVI_20220101_20220701_Lombardia_S3_2_masked.nc\",\n",
    "        known_hash=\"md5:be3f16913ebbdb4e7af227f971007b22\",\n",
    "        path=f\".\",)    \n",
    "    cgls_ds = xr.open_dataset(cgls_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bd869-28cf-4a15-babb-ea2370b30b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgls_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224f971-6ab1-4db3-992f-a64dce84d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_AOI = cgls_ds.NDVI.rio.write_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d385fbe-26a2-4f67-9ec7-026beb52dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_AOI = NDVI_AOI.rio.clip(AOI_poly, crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19678a-758b-446a-a198-f66849e39085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NDVI_AOI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b3d48-a0ed-4ae8-8b7f-48e55823e8ee",
   "metadata": {},
   "source": [
    "The nominal spatial resolution of the Long term statistics is 1km. As the current NDVI product has a nominal spatial resolution of 300m a re projection is needed. RioXarray through RasterIO that wraps the GDAL method can take care of this. More info about all the options can be found [here](https://rasterio.readthedocs.io/en/stable/api/rasterio.warp.html#rasterio.warp.reproject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80a2e8-80ba-44e3-a51b-e8476b465a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1k = NDVI_AOI.rio.reproject_match(LTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017d9ac-5d82-4280-9f4c-92ce7622ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1k = NDVI_1k.rename({'x': 'lon', 'y':'lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229b0ef-13d1-4443-b5bd-708eaf8b8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCI = ((NDVI_1k - LTS['min']) / (LTS['max'] - LTS['min'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b857e-7627-4d88-a83d-f3719a7f5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5829a5-4294-4ccf-906b-213344db0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCI.name = 'VCI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6112f-0bd5-41de-8374-547636380ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36567b-8d2e-4f37-83a6-9f8062d05717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "VCI_c = VCI.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e7977-804f-450d-af2d-dfb7552d3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCI.isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d7df1-b4f8-47e6-bbe3-ad29601ddf13",
   "metadata": {},
   "source": [
    "Now you have catalogue, original data source, both on cloud space, thus even from daks workers which does not have access to your NFS local disk space, datas are accessible.\n",
    "Now you are ready to parallelize your analysis using dask workers from dask gateway!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67cb31-b8f2-4d91-a37f-95d2a4ca328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1f23a-8838-41fe-96d7-4f7b0fb9cc3f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <i class=\"fa-check-circle fa\" style=\"font-size: 22px;color:#666;\"></i> <b>Key Points</b>\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>Chunking and compression</li>\n",
    "        <li>Dask</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94605e-64e6-4a1a-a406-0bcf3dccc73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
